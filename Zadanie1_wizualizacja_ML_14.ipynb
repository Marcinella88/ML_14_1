{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc88f29c",
   "metadata": {},
   "source": [
    "**Import bibliotek + import bazy danych**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy import where\n",
    "from numpy import meshgrid\n",
    "from numpy import arange\n",
    "from numpy import hstack\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "target = 'Diabetic'\n",
    "X, y = diabetes[features], diabetes[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8a414",
   "metadata": {},
   "source": [
    "**Podział danych na zbiór treningowy oraz zbiór testowy + standaryzacja zbiorów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa89f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['Pregnancies', 'Age']], y, test_size=0.30, random_state=0, stratify=y)\n",
    "\n",
    "scaler_2var = StandardScaler()\n",
    "X_train_standardized = scaler_2var.fit_transform(X_train)\n",
    "X_test_standardized = scaler_2var.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05951e51",
   "metadata": {},
   "source": [
    "**Zdefiniowanie funkcji: plot_classification_surface:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_LR(penalty,C):\n",
    "    global model_list\n",
    "    \n",
    "    if penalty==\"l1\":\n",
    "        model = LogisticRegression(penalty=penalty,C=C,solver='liblinear')\n",
    "    elif penalty==\"l2\":\n",
    "        model = LogisticRegression(penalty=penalty,C=C)\n",
    "    elif penalty==\"elasticnet\":\n",
    "        model = LogisticRegression(penalty=penalty,C=C,solver='saga', l1_ratio=0.1)\n",
    "    else:\n",
    "        raise ValueError(\"Nieprawidłowa wartość 'penalty'\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dbb77b",
   "metadata": {},
   "source": [
    "**Zdefiniowanie funkcji: plot_classification_surface:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e38971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_surface(X_plot, y_plot, trained_model):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    min1, max1 = X_plot[:, 0].min()-1, X_plot[:, 0].max()+1\n",
    "    min2, max2 = X_plot[:, 1].min()-1, X_plot[:, 1].max()+1\n",
    "\n",
    "    x1grid = arange(min1, max1, 0.1)\n",
    "    x2grid = arange(min2, max2, 0.1)\n",
    "\n",
    "    xx, yy = meshgrid(x1grid, x2grid)\n",
    "\n",
    "    r1, r2 = xx.flatten(), yy.flatten()\n",
    "    r1, r2 = r1.reshape((len(r1), 1)), r2.reshape((len(r2), 1))\n",
    "\n",
    "    grid = hstack((r1,r2))\n",
    "\n",
    "    yhat = trained_model.predict(grid)\n",
    "\n",
    "    zz = yhat.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, zz, cmap='Paired')\n",
    "\n",
    "    for class_value in range(2):\n",
    "\n",
    "        row_ix = where(y_plot == class_value)\n",
    "        plt.scatter(X_plot[row_ix, 0], X_plot[row_ix, 1], cmap='Paired', alpha=0.3, label=class_value)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffb30d",
   "metadata": {},
   "source": [
    "**Zdefiniowanie funkcji calculate_metrics_new:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ad8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dataframe = pd.DataFrame(columns=[\n",
    "    'Model', 'Penalty', 'Par_C','F1_train',\n",
    "    'F1_test', 'AUC', 'Accuracy', 'Precision', 'Recall'\n",
    "])\n",
    "\n",
    "def calculate_metrics_new(model, name, X_test, y_test, X_train, y_train):\n",
    "    global metrics_dataframe\n",
    "    predictions_test = model.predict(X_test)\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    try:\n",
    "        name_title = f\"{name}\"\n",
    "        penalty = model.get_params()['penalty']\n",
    "        C_value = model.get_params()['C']\n",
    "    except:\n",
    "        penalty = \"UNKNOWN\"\n",
    "        C_value = \"UNKNOWN\"    \n",
    "    \n",
    "    print(f\"\\n Model: {name_title} - penalty:{penalty}, parametr C:{C_value}\")\n",
    "   \n",
    "    plot_classification_surface(X_train, y_train, model)\n",
    "    \n",
    "    f1_metric_train = round(f1_score(y_train, predictions_train),4)\n",
    "    f1_metric_test = round(f1_score(y_test, predictions_test),4)\n",
    "    auc_metric = round(roc_auc_score(y_test, predictions_proba),4)\n",
    "    acc_metric = round(accuracy_score(y_test, predictions_test),4)\n",
    "    prec_metric = round(precision_score(y_test, predictions_test),4)\n",
    "    rec_metric = round(recall_score(y_test, predictions_test),4)\n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'Model': name,\n",
    "        'Penalty': penalty,\n",
    "        'Par_C': C_value,\n",
    "        'F1_train': f1_metric_train,\n",
    "        'F1_test': f1_metric_test,\n",
    "        'AUC': auc_metric,\n",
    "        'Accuracy': acc_metric,\n",
    "        'Precision': prec_metric,\n",
    "        'Recall': rec_metric\n",
    "    }])\n",
    "\n",
    "    metrics_dataframe = pd.concat([metrics_dataframe, new_row], ignore_index=True)\n",
    "    return metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569ead6e",
   "metadata": {},
   "source": [
    "**Zdefiniowanie zbiorów parametrów: \"penalties\" i \"parametrs_C\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = ['l1', 'l2', 'elasticnet']\n",
    "parametrs_C = [0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c8f9f",
   "metadata": {},
   "source": [
    "**Uruchomienie pętli generującej, trenującej modele oraz wyświetlającej zbiór metryk wygenerownych modeli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b48fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for penalty in penalties:\n",
    "    for C in parametrs_C:\n",
    "      label = f\"Logistic Regression\"  \n",
    "      model = generate_model_LR(penalty,C)\n",
    "      model.fit(X_train_standardized,y_train)\n",
    "      metrics_dataframe = calculate_metrics_new(model, label, X_test_standardized, y_test, X_train_standardized, y_train)\n",
    "display(metrics_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d957bd2",
   "metadata": {},
   "source": [
    "**WNIOSKI:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Modele regresji logistycznej z różnymi rodzajami regularyzacji: {penalties} oraz ich stopniem: {parametrs_C} wskazują praktycznie takie same wyniki dla metryk takich jak:\")\n",
    "print(f\"Dokładność (Accuracy) – zakres: {round(metrics_dataframe['Accuracy'].min(), 4)} - {round(metrics_dataframe['Accuracy'].max(), 4)}\")\n",
    "print(f\"Precyzja (Precision) – zakres: {round(metrics_dataframe['Precision'].min(), 4)} - {round(metrics_dataframe['Precision'].max(), 4)}\")\n",
    "print(f\"Czułość (Recall) – zakres: {round(metrics_dataframe['Recall'].min(), 4)} - {round(metrics_dataframe['Recall'].max(), 4)}\")\n",
    "\n",
    "print(\"\\nModel regresji logistycznej nie uzyskuje dobrych wyników – nawet przy zmianie wartości regularyzacji i jego stopnia, metryki pozostają dość niskie.\")\n",
    "print(\"Oznacza to, że na podstawie jedynie zmiennych 'Pregnancies' oraz 'Age' model nie jest w stanie skutecznie przewidywać zmiennej 'Diabetics'.\")\n",
    "\n",
    "print(f\"\\nMetrykę F1:\")\n",
    "print(f\"Dla zbiorów treningowych – zakres F1: {round(metrics_dataframe['F1_train'].min(), 4)} - {round(metrics_dataframe['F1_train'].max(), 4)}\")\n",
    "print(f\"Dla zbiorów testowych – zakres F1: {round(metrics_dataframe['F1_test'].min(), 4)} - {round(metrics_dataframe['F1_test'].max(), 4)}\")\n",
    "\n",
    "print(\"\\nWeryfikując metrykę F1 nie widać oznak przetrenowania – dla danych testowych F1 nie różni się znacznie od F1 dla danych treningowych.\")\n",
    "print(\"\\nModel raczej wymaga dotrenowania, biorąc pod uwagę ogólnie niski poziom F1 dla obu zbiorów danych.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
